import type { ActionExample } from "@elizaos/core";

export const transcribeVideoExamples: ActionExample[][] = [
    [
        {
            user: "{{user1}}",
            content: {
                text: "Can you transcribe this video for me? The link is https://www.youtube.com/watch?v=TsrTlw76scI",
            },
        },
        {
            user: "{{agent}}",
            content: {
                text: "Yes sure, let me transcribe it.",
                action: "TRANSCRIBE_VIDEO",
            },
        },
        {
            user: "{{agent}}",
            content: {
                text: "Here is the transcribed text for you:  AI agents are one of the most exciting developments in the AI space right now. And I think ELISA is the best AI agent framework that's available. For one, it's open source. Two, it's compatible with JavaScript. And three, it's actually really easy to learn and use and even develop on. So I wanted to learn more about ELISA and I spent the past few days just developing a plugin for it and just learning about all the concepts. I just want to show you that right now. So the plugin, it makes use of the Open Weather API. It's a 1,000 free API calls today. I mean, just for free every day. And you can get the weather from any city in the world. So to show you how that works, I already have ELISA set up right here. And I'm just going to go to the client, the chat client right here. Select my agent, ELISA, and chat. And I'm just going to say hello. And right now I'm just using the chat GPT LLM for the LLM of ELISA. So I'll go over that a bit later too. So I say hello. I say, what's the weather today? What's the weather like today? It should be smart enough to know that. Or rather, it just doesn't know where I am right now. So it should ask where I'm asking for. And I say Toronto. And then it should use my plugin to fetch the action. Or rather, call the API to fetch the weather for Toronto. And it returns it right there. And if I ask for another place, like what about in Tokyo? Then it should know to fetch exactly. So right there. It fetches the weather, spits it out, six degrees Celsius, and feels like three Celsius. So that's my little plugin, my little weather plugin. And I just want to show you, this is how it looks like right now. This is the plugin template. It's got a name, description, actions, evaluators, and providers. So for ELISA, those are the main concepts. You got the agent runtime, which is the kind of runtime that combines the LLM with the actions and providers and evaluators. And you got the actions, which are like, I guess they are like literally actions. They are things that you code explicitly. And if the agent decides to run it, then it will run your handler and it will return the response. So because my plugin is just really simple, it doesn't have any evaluators or plugins. I mean, evaluators, providers, it just has an action. It's the get current weather action. And this is the whole thing right here. So again, it has a name, description. So then the agent knows what the action is called and when it should use it. So get the current weather for a given location. But just to buffer this at the same time, it also has a section for examples. So using these examples, you can kind of prompt the agent to know in which situation it should ask or use this plugin. So for example, user 1, what's the weather like right now? Agent says, in what city? User 1 says, Tokyo. Agent says, we will get the current weather for you. And then inside the content, it actually has an action parameter too, which is get current weather. And that is the name of the action. So it knows that's when it should call it. And another example is just the same thing. These are just kind of just basic ideas. They're literally examples that the LLM will consider when running. And so back to the action. You have that. And then you have the validate, which determines whether the action should run or not. And in this case, we just say, if the agent decides to call this action and whether this action should run or not is based on whether it has the open weather config, which is just the API key right now. So in the environment file, we have the open weather API key. And I can't show you my exact key, but basically you just fill in your key right here. And then it'll pull that in and then it'll return true. So then it'll validate. And once that's true, it'll go to the handler. And for the handler, it's like about two or three main parts. The first part is just the content, the context, and the state. So the main thing here is the content. And the content is just the context hydrated with the state. So yeah, the content is just, you can think of it as one gigantic prompt. It's the prompt of that the LLM is going to ask and it has all the context that is needed or that should be provided that you want in there. So that's the context. And the context is just a template with some variables to be hydrated with. And the state are the variables that it hydrates it with. So in this one, we can see the template is the get weather template. So in our example, we just say Toronto. But how does it know how to construct the query with just Toronto? Like what's the country and all that stuff? So this is the template that determines it. It says respond with the JSON object containing the location information. And this is the format that it should respond in. So it has the city and the country. And then once you have that context, you call this function generate message response. And then you put in the context and you put in the runtime. And in this function, you have the generate text, which calls the LLM with that context. And then it knows to return that information. So basically the city, the country. And once you have the city and the country, you can do stuff with it. You can call the API with it. So if it has a city and a country, or if it doesn't have that, it returns and doesn't do anything. But if it does, then it creates an API service for calling the open weather API. And then it gets the weather. So right here, just a little service with a function get weather. And then it takes the city and the country from the previous call and then constructs the location, the URL, and then it returns it. Back as weather data, as the variable. And then you can use that variable to call back. So that basically tells the agent, the LLM, to respond back with this text. So that's what it does right here. Yeah, so that's my little plug-in. I had fun developing it. And I think it's going to be fairly interesting for the next year or so, just this shift that we're going to see with more agents use. And I think it's going to be interesting. Like when you build an agentic app, there's an idea that I've been hearing. A lot more apps are going to be where the agent comes to you rather than the user go to the app. Because it's a lot easier if you think about it. If you're going to build an agentic app, it's going to be a lot harder to onboard your client or customer or whoever. So to onboard them to a new site with a new account, you have to create it. And then they have to get familiar with the whole new UX flow. But rather, you can just bring the agent to where they are right now, let's say X. And then because it already has that functionality built in, let's say getting the weather or maybe interacting with Notion or wherever your favorite platform is. So I think that's something to look out for and just something I want to explore more. So yeah, Eliza has been really great. I had a lot of fun building it and building this plugin for Eliza. And yeah, I just want to explore more of this. So I hope that helps. If there's anything else, just let me know in the comments.",
            },
        },
    ],
];
